{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(pd.read_csv('mnist_train1.csv'))\n",
    "df2=pd.DataFrame(pd.read_csv('mnist_test1.csv'))\n",
    "\n",
    "x_train1 = df.drop('label',axis=1)\n",
    "y_train = df['label']\n",
    "x_test1  = df2.drop('label',axis=1)\n",
    "y_test  = df2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization done in 1.308s\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(x_train1)\n",
    "x_train=scaler.transform(x_train1)\n",
    "x_test=scaler.transform(x_test1)\n",
    "print(\"Standardization done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA transformation done in 12.315s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "pca=PCA(0.9)\n",
    "pca.fit(x_train)\n",
    "x_train=pca.transform(x_train)\n",
    "x_test=pca.transform(x_test)\n",
    "print(\"PCA transformation done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with knn done in 3.467s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model= KNeighborsClassifier(n_neighbors=1,p=2)\n",
    "model.fit(x_train,y_train)\n",
    "print(\"Training with knn done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in training set is 1.0\n",
      "The accuracy in testing set is 0.9734\n",
      "[[ 973    1    1    0    0    1    1    2    1    0]\n",
      " [   0 1130    3    0    1    0    1    0    0    0]\n",
      " [   5    1 1008    3    1    0    2   11    1    0]\n",
      " [   1    1    2  969    1   17    0    7    8    4]\n",
      " [   0    2    0    0  952    0    2    3    1   22]\n",
      " [   1    1    0    6    2  865    6    1    6    4]\n",
      " [   4    2    0    0    2    4  946    0    0    0]\n",
      " [   0   13    6    2    4    0    0  996    0    7]\n",
      " [   4    1    2   14    5   10    2    5  927    4]\n",
      " [   1    3    1    5   13    6    1   10    1  968]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.98      1.00      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       0.97      0.96      0.96      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.96      0.97      0.96       892\n",
      "           6       0.98      0.99      0.99       958\n",
      "           7       0.96      0.97      0.97      1028\n",
      "           8       0.98      0.95      0.97       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accur_train = []\n",
    "accur = []\n",
    "predictions_train=model.predict(x_train)\n",
    "predictions_test=model.predict(x_test)\n",
    "print(\"The accuracy in training set is {}\".format(accuracy_score(predictions_train,y_train)))#format(model.score(x_train,y_train)))\n",
    "print(\"The accuracy in testing set is {}\".format(accuracy_score(predictions_test,y_test)))#format(model.score(x_test,y_test)))\n",
    "print(confusion_matrix(y_test,predictions_test))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions_test))\n",
    "accur_train.append(accuracy_score(predictions_train,y_train))\n",
    "accur.append(accuracy_score(predictions_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with knn done in 3.938s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model= KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "model.fit(x_train,y_train)\n",
    "print(\"Training with knn done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in training set is 0.9886\n",
      "The accuracy in testing set is 0.9735\n",
      "[[ 974    1    1    0    0    1    2    1    0    0]\n",
      " [   0 1131    3    0    0    0    1    0    0    0]\n",
      " [   7    4 1002    2    1    0    0   14    2    0]\n",
      " [   0    1    5  977    1   11    0    7    5    3]\n",
      " [   2    6    0    0  952    0    4    2    0   16]\n",
      " [   3    1    0    9    2  866    4    1    2    4]\n",
      " [   5    3    0    0    2    3  945    0    0    0]\n",
      " [   0   16    6    0    2    0    0  998    0    6]\n",
      " [   6    1    3   15    6   13    3    3  921    3]\n",
      " [   5    5    2    9    9    3    1    3    3  969]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.97      1.00      0.98      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.97      0.97      0.97       892\n",
      "           6       0.98      0.99      0.99       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.99      0.95      0.97       974\n",
      "           9       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train=model.predict(x_train)\n",
    "predictions_test=model.predict(x_test)\n",
    "print(\"The accuracy in training set is {}\".format(accuracy_score(predictions_train,y_train)))#format(model.score(x_train,y_train)))\n",
    "print(\"The accuracy in testing set is {}\".format(accuracy_score(predictions_test,y_test)))#format(model.score(x_test,y_test)))\n",
    "print(confusion_matrix(y_test,predictions_test))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions_test))\n",
    "accur_train.append(accuracy_score(predictions_train,y_train))\n",
    "accur.append(accuracy_score(predictions_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in training set is 0.80745\n",
      "The accuracy in testing set is 0.8196\n",
      "[[ 877    0    7    2    2   58   25    1    7    1]\n",
      " [   0 1092   10    3    0    7    3    0   20    0]\n",
      " [  19   72  780   33   31    3   23   18   50    3]\n",
      " [   4   24   26  812    1   50    8   14   57   14]\n",
      " [   1   22    2    0  811    3   16    1   10  116]\n",
      " [  12   63    2  118   21  611   27   10   13   15]\n",
      " [  18   26   23    0   31   33  826    0    1    0]\n",
      " [   2   59   21    1   20    2    0  856   13   54]\n",
      " [  14   39   11   84   13   35   13    9  718   38]\n",
      " [  16   22    7   10   85   12    1   26   17  813]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       980\n",
      "           1       0.77      0.96      0.86      1135\n",
      "           2       0.88      0.76      0.81      1032\n",
      "           3       0.76      0.80      0.78      1010\n",
      "           4       0.80      0.83      0.81       982\n",
      "           5       0.75      0.68      0.72       892\n",
      "           6       0.88      0.86      0.87       958\n",
      "           7       0.92      0.83      0.87      1028\n",
      "           8       0.79      0.74      0.76       974\n",
      "           9       0.77      0.81      0.79      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(x_train, y_train)\n",
    "predictions_train=clf.predict(x_train)\n",
    "predictions_test=clf.predict(x_test)\n",
    "print(\"The accuracy in training set is {}\".format(accuracy_score(predictions_train,y_train)))#format(model.score(x_train,y_train)))\n",
    "print(\"The accuracy in testing set is {}\".format(accuracy_score(predictions_test,y_test)))#format(model.score(x_test,y_test)))\n",
    "print(confusion_matrix(y_test,predictions_test))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions_test))\n",
    "accur_train.append(accuracy_score(predictions_train,y_train))\n",
    "accur.append(accuracy_score(predictions_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.9886, 0.80745]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9734, 0.9735, 0.8196]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
